"""
FULL GAIN 2.0 - Moteur V4 ULTIMATE
Le moteur le plus avanc√© avec:
- Machine Learning (Random Forest + Gradient Boosting)
- Backtesting automatique avec ROI/CLV
- Auto-ajustement des pond√©rations
- Ensemble de mod√®les
- Calibration des probabilit√©s
"""
import os
import math
import json
import pickle
import hashlib
import numpy as np
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import Optional, Dict, List, Tuple, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, field, asdict

# Reality Check Integration
try:
    import sys
    sys.path.insert(0, "/app")
    from agents.reality_check import RealityChecker
    REALITY_CHECK_ENABLED = True
except ImportError:
    REALITY_CHECK_ENABLED = False
from enum import Enum
import logging
from pathlib import Path

# ML imports
try:
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.calibration import CalibratedClassifierCV
    from sklearn.model_selection import cross_val_score, train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, brier_score_loss
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    logging.warning("scikit-learn non disponible - ML d√©sactiv√©")

logger = logging.getLogger(__name__)


# ============================================================
# CONFIGURATION
# ============================================================

MODEL_DIR = Path('/app/models')
MODEL_DIR.mkdir(exist_ok=True)


class Confidence(Enum):
    DIAMOND = "diamond"
    PLATINUM = "platinum"
    GOLD = "gold"
    SILVER = "silver"
    BRONZE = "bronze"
    IRON = "iron"


class Recommendation(Enum):
    DIAMOND_PICK = "üíé DIAMOND PICK"
    STRONG_YES = "‚úÖ STRONG YES"
    YES = "‚úÖ YES"
    LEAN_YES = "üìà LEAN YES"
    NEUTRAL = "‚öñÔ∏è NEUTRAL"
    LEAN_NO = "üìâ LEAN NO"
    NO = "‚ùå NO"
    STRONG_NO = "‚ùå STRONG NO"


# Home advantage par ligue
HOME_ADVANTAGE = {
    'Premier League': 1.15,
    'Ligue 1': 1.25,
    'Bundesliga': 1.20,
    'Serie A': 1.30,
    'La Liga': 1.25,
    'Champions League': 1.10,
    'default': 1.20
}


# ============================================================
# DATACLASSES
# ============================================================

@dataclass
class FeatureSet:
    """Features pour le ML"""
    # Home team
    home_btts_pct: float
    home_over25_pct: float
    home_avg_scored: float
    home_avg_conceded: float
    home_clean_sheet_pct: float
    home_fts_pct: float
    home_last5_btts: float
    home_last5_over25: float
    home_form_points: int
    home_momentum: float
    home_matches: int
    
    # Away team
    away_btts_pct: float
    away_over25_pct: float
    away_avg_scored: float
    away_avg_conceded: float
    away_clean_sheet_pct: float
    away_fts_pct: float
    away_last5_btts: float
    away_last5_over25: float
    away_form_points: int
    away_momentum: float
    away_matches: int
    
    # H2H
    h2h_btts_pct: float
    h2h_over25_pct: float
    h2h_avg_goals: float
    h2h_matches: int
    
    # Computed
    total_xg: float
    home_advantage: float
    
    def to_array(self) -> np.ndarray:
        """Convertit en array numpy pour ML"""
        return np.array([
            self.home_btts_pct, self.home_over25_pct, self.home_avg_scored,
            self.home_avg_conceded, self.home_clean_sheet_pct, self.home_fts_pct,
            self.home_last5_btts, self.home_last5_over25, self.home_form_points,
            self.home_momentum, self.home_matches,
            self.away_btts_pct, self.away_over25_pct, self.away_avg_scored,
            self.away_avg_conceded, self.away_clean_sheet_pct, self.away_fts_pct,
            self.away_last5_btts, self.away_last5_over25, self.away_form_points,
            self.away_momentum, self.away_matches,
            self.h2h_btts_pct, self.h2h_over25_pct, self.h2h_avg_goals, self.h2h_matches,
            self.total_xg, self.home_advantage
        ]).reshape(1, -1)


@dataclass
class BacktestResult:
    """R√©sultat de backtesting"""
    total_bets: int
    wins: int
    losses: int
    win_rate: float
    roi: float
    avg_odds: float
    profit_units: float
    max_drawdown: float
    sharpe_ratio: float
    clv: float  # Closing Line Value
    by_confidence: Dict[str, Dict]


@dataclass
class ModelPerformance:
    """Performance d'un mod√®le"""
    accuracy: float
    precision: float
    recall: float
    f1: float
    brier_score: float
    cv_scores: List[float]


# ============================================================
# MACHINE LEARNING MODULE
# ============================================================

class MLPredictor:
    """
    Module Machine Learning pour pr√©dictions
    - Random Forest
    - Gradient Boosting
    - Ensemble voting
    - Calibration des probabilit√©s
    """
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.is_trained = False
        self.feature_names = [
            'home_btts_pct', 'home_over25_pct', 'home_avg_scored',
            'home_avg_conceded', 'home_clean_sheet_pct', 'home_fts_pct',
            'home_last5_btts', 'home_last5_over25', 'home_form_points',
            'home_momentum', 'home_matches',
            'away_btts_pct', 'away_over25_pct', 'away_avg_scored',
            'away_avg_conceded', 'away_clean_sheet_pct', 'away_fts_pct',
            'away_last5_btts', 'away_last5_over25', 'away_form_points',
            'away_momentum', 'away_matches',
            'h2h_btts_pct', 'h2h_over25_pct', 'h2h_avg_goals', 'h2h_matches',
            'total_xg', 'home_advantage'
        ]
    
    def _create_models(self, target: str):
        """Cr√©e les mod√®les pour un target (btts ou over25)"""
        rf = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        gb = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            min_samples_split=5,
            random_state=42
        )
        
        return {
            'random_forest': rf,
            'gradient_boosting': gb
        }
    
    def train(self, X: np.ndarray, y_btts: np.ndarray, y_over25: np.ndarray) -> Dict:
        """
        Entra√Æne les mod√®les
        
        Returns:
            Performance metrics
        """
        if not ML_AVAILABLE:
            return {'error': 'ML non disponible'}
        
        results = {}
        
        for target, y in [('btts', y_btts), ('over25', y_over25)]:
            logger.info(f"Training models for {target}...")
            
            # Scaler
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            self.scalers[target] = scaler
            
            # Split
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.2, random_state=42
            )
            
            # Train models
            self.models[target] = {}
            target_results = {}
            
            for name, model in self._create_models(target).items():
                # Train
                model.fit(X_train, y_train)
                
                # Calibrate
                calibrated = CalibratedClassifierCV(model, cv=3, method='isotonic')
                calibrated.fit(X_train, y_train)
                
                self.models[target][name] = calibrated
                
                # Evaluate
                y_pred = calibrated.predict(X_test)
                y_proba = calibrated.predict_proba(X_test)[:, 1]
                
                cv_scores = cross_val_score(model, X_scaled, y, cv=5)
                
                target_results[name] = {
                    'accuracy': accuracy_score(y_test, y_pred),
                    'precision': precision_score(y_test, y_pred, zero_division=0),
                    'recall': recall_score(y_test, y_pred, zero_division=0),
                    'f1': f1_score(y_test, y_pred, zero_division=0),
                    'brier_score': brier_score_loss(y_test, y_proba),
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std()
                }
            
            results[target] = target_results
        
        self.is_trained = True
        return results
    
    def predict(self, features: FeatureSet, target: str) -> Dict:
        """
        Pr√©dit avec ensemble de mod√®les
        
        Returns:
            Probabilit√© moyenne + par mod√®le
        """
        if not self.is_trained or target not in self.models:
            return {'probability': None, 'error': 'Mod√®le non entra√Æn√©'}
        
        X = features.to_array()
        X_scaled = self.scalers[target].transform(X)
        
        predictions = {}
        probas = []
        
        for name, model in self.models[target].items():
            proba = model.predict_proba(X_scaled)[0, 1]
            predictions[name] = round(proba * 100, 1)
            probas.append(proba)
        
        # Ensemble (moyenne)
        ensemble_proba = np.mean(probas)
        
        return {
            'probability': round(ensemble_proba * 100, 1),
            'by_model': predictions,
            'confidence_interval': (
                round(min(probas) * 100, 1),
                round(max(probas) * 100, 1)
            )
        }
    
    def save(self, path: Path = MODEL_DIR):
        """Sauvegarde les mod√®les"""
        if not self.is_trained:
            return
        
        for target in ['btts', 'over25']:
            with open(path / f'ml_models_{target}.pkl', 'wb') as f:
                pickle.dump({
                    'models': self.models.get(target, {}),
                    'scaler': self.scalers.get(target)
                }, f)
        
        logger.info(f"Mod√®les sauvegard√©s dans {path}")
    
    def load(self, path: Path = MODEL_DIR) -> bool:
        """Charge les mod√®les"""
        try:
            for target in ['btts', 'over25']:
                model_path = path / f'ml_models_{target}.pkl'
                if model_path.exists():
                    with open(model_path, 'rb') as f:
                        data = pickle.load(f)
                        self.models[target] = data['models']
                        self.scalers[target] = data['scaler']
            
            self.is_trained = bool(self.models)
            return self.is_trained
        except Exception as e:
            logger.error(f"Erreur chargement mod√®les: {e}")
            return False
    
    def get_feature_importance(self, target: str) -> Dict[str, float]:
        """Retourne l'importance des features"""
        if target not in self.models:
            return {}
        
        # Utiliser Random Forest pour l'importance
        rf_model = self.models[target].get('random_forest')
        if rf_model and hasattr(rf_model, 'estimator'):
            importances = rf_model.estimator.feature_importances_
            return dict(zip(self.feature_names, importances))
        
        return {}


# ============================================================
# BACKTESTING MODULE
# ============================================================

class Backtester:
    """
    Module de Backtesting
    - Simulation sur donn√©es historiques
    - ROI, CLV, Sharpe Ratio
    - Analyse par niveau de confiance
    """
    
    def __init__(self, db_config: Dict):
        self.db_config = db_config
    
    def _get_conn(self):
        return psycopg2.connect(**self.db_config)
    
    def run_backtest(self, strategy: str = 'btts', 
                     min_score: float = 65,
                     min_confidence: str = 'gold',
                     stake: float = 1.0,
                     start_date: str = None) -> BacktestResult:
        """
        Ex√©cute un backtest
        
        Args:
            strategy: 'btts' ou 'over25'
            min_score: Score minimum pour parier
            min_confidence: Niveau de confiance minimum
            stake: Mise par pari (unit√©s)
            start_date: Date de d√©but (YYYY-MM-DD)
        """
        conn = self._get_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # R√©cup√©rer les matchs termin√©s avec pr√©dictions
        query = """
            SELECT 
                mp.*,
                mr.score_home,
                mr.score_away,
                mr.outcome
            FROM market_predictions mp
            JOIN match_results mr ON mp.home_team = mr.home_team 
                                  AND mp.away_team = mr.away_team
            WHERE mr.is_finished = true
        """
        if start_date:
            query += f" AND mp.match_date >= '{start_date}'"
        
        cur.execute(query)
        matches = cur.fetchall()
        cur.close()
        conn.close()
        
        # Simuler les paris
        results = {
            'bets': [],
            'by_confidence': {c.value: {'bets': 0, 'wins': 0, 'profit': 0} for c in Confidence}
        }
        
        bankroll = 100.0  # Bankroll initial
        peak_bankroll = bankroll
        max_drawdown = 0
        
        for match in matches:
            if strategy == 'btts':
                score = match.get('btts_score', 0)
                confidence = match.get('btts_confidence', 'iron')
                odds = match.get('odds_btts_yes', 1.9)
                actual_btts = match['score_home'] > 0 and match['score_away'] > 0
                won = actual_btts
            else:
                score = match.get('over25_score', 0)
                confidence = match.get('over25_confidence', 'iron')
                odds = match.get('odds_over25', 1.85)
                actual_over25 = (match['score_home'] + match['score_away']) > 2
                won = actual_over25
            
            # Filtrer selon crit√®res
            if score < min_score:
                continue
            
            confidence_order = ['diamond', 'platinum', 'gold', 'silver', 'bronze', 'iron']
            if confidence_order.index(confidence) > confidence_order.index(min_confidence):
                continue
            
            # Calculer profit
            profit = stake * (odds - 1) if won else -stake
            bankroll += profit
            
            # Drawdown
            if bankroll > peak_bankroll:
                peak_bankroll = bankroll
            drawdown = (peak_bankroll - bankroll) / peak_bankroll
            max_drawdown = max(max_drawdown, drawdown)
            
            results['bets'].append({
                'match': f"{match['home_team']} vs {match['away_team']}",
                'score': score,
                'confidence': confidence,
                'odds': odds,
                'won': won,
                'profit': profit
            })
            
            results['by_confidence'][confidence]['bets'] += 1
            results['by_confidence'][confidence]['wins'] += 1 if won else 0
            results['by_confidence'][confidence]['profit'] += profit
        
        # Calculer m√©triques
        total_bets = len(results['bets'])
        wins = sum(1 for b in results['bets'] if b['won'])
        total_profit = sum(b['profit'] for b in results['bets'])
        avg_odds = np.mean([b['odds'] for b in results['bets']]) if results['bets'] else 0
        
        # Sharpe ratio (simplifi)
        if results['bets']:
            returns = [b['profit'] / stake for b in results['bets']]
            sharpe = np.mean(returns) / np.std(returns) if np.std(returns) > 0 else 0
        else:
            sharpe = 0
        
        return BacktestResult(
            total_bets=total_bets,
            wins=wins,
            losses=total_bets - wins,
            win_rate=wins / total_bets * 100 if total_bets > 0 else 0,
            roi=total_profit / (total_bets * stake) * 100 if total_bets > 0 else 0,
            avg_odds=avg_odds,
            profit_units=total_profit,
            max_drawdown=max_drawdown * 100,
            sharpe_ratio=sharpe,
            clv=0,  # √Ä calculer avec les closing lines
            by_confidence=results['by_confidence']
        )


# ============================================================
# AUTO-CALIBRATION MODULE
# ============================================================

class AutoCalibrator:
    """
    Auto-ajustement des pond√©rations bas√© sur performance historique
    """
    
    def __init__(self, db_config: Dict):
        self.db_config = db_config
        self.weights_file = MODEL_DIR / 'calibrated_weights.json'
        self.default_weights = {
            'poisson': 0.35,
            'global': 0.15,
            'specific': 0.20,
            'trends': 0.15,
            'h2h': 0.15
        }
    
    def load_weights(self) -> Dict:
        """Charge les poids calibr√©s"""
        if self.weights_file.exists():
            with open(self.weights_file) as f:
                return json.load(f)
        return self.default_weights.copy()
    
    def save_weights(self, weights: Dict):
        """Sauvegarde les poids"""
        with open(self.weights_file, 'w') as f:
            json.dump(weights, f, indent=2)
    
    def calibrate(self, backtest_results: List[Dict]) -> Dict:
        """
        Calibre les poids bas√© sur les r√©sultats de backtest
        
        Principe: augmenter le poids des facteurs qui ont bien pr√©dit,
        diminuer ceux qui ont mal pr√©dit
        """
        if not backtest_results:
            return self.default_weights.copy()
        
        # Analyser quels facteurs corr√®lent avec le succ√®s
        factor_success = {k: [] for k in self.default_weights.keys()}
        
        for result in backtest_results:
            factors = result.get('factors', {})
            won = result.get('won', False)
            
            for factor, value in factors.items():
                if factor in factor_success:
                    # Si le facteur √©tait √©lev√© et on a gagn√©, c'est positif
                    # Si le facteur √©tait √©lev√© et on a perdu, c'est n√©gatif
                    correlation = value / 100 if won else -value / 100
                    factor_success[factor].append(correlation)
        
        # Calculer nouveaux poids bas√©s sur corr√©lation moyenne
        new_weights = {}
        total = 0
        
        for factor, correlations in factor_success.items():
            if correlations:
                # Score = moyenne des corr√©lations + baseline
                score = 0.5 + np.mean(correlations) * 0.5
                score = max(0.05, min(0.5, score))  # Clamp
            else:
                score = self.default_weights[factor]
            
            new_weights[factor] = score
            total += score
        
        # Normaliser pour que somme = 1
        new_weights = {k: v / total for k, v in new_weights.items()}
        
        self.save_weights(new_weights)
        return new_weights


# ============================================================
# MOTEUR V4 ULTIMATE
# ============================================================

class PredictionEngineUltimate:
    """
    Moteur V4 ULTIMATE - Le plus avanc√©
    
    Combine:
    - Mod√®le Poisson
    - Machine Learning (ensemble)
    - Backtesting
    - Auto-calibration
    - Analyse multi-facteurs
    """
    
    def __init__(self):
        self.db_config = {
            'host': os.getenv('DB_HOST', '127.0.0.1'),
            'port': 5432,
            'database': os.getenv('DB_NAME', 'monps_db'),
            'user': os.getenv('DB_USER', 'monps_user'),
            'password': os.getenv('DB_PASSWORD', 'monps_secure_password_2024')
        }
        
        self.ml = MLPredictor()
        self.backtester = Backtester(self.db_config)
        self.calibrator = AutoCalibrator(self.db_config)
        
        # Charger mod√®les ML si disponibles
        self.ml.load()
        
        # Charger poids calibr√©s
        self.weights = self.calibrator.load_weights()
    
    def _get_conn(self):
        return psycopg2.connect(**self.db_config)
    
    def _safe_float(self, value, default: float = 50.0) -> float:
        if value is None:
            return default
        try:
            return float(value)
        except:
            return default
    
    # ============================================================
    # POISSON MODEL
    # ============================================================
    
    def _poisson_prob(self, lam: float, k: int) -> float:
        if lam <= 0:
            return 1.0 if k == 0 else 0.0
        return (lam ** k) * math.exp(-lam) / math.factorial(k)
    
    def calculate_poisson(self, home_xg: float, away_xg: float, max_goals: int = 7) -> Dict:
        """Calcule probabilit√©s via Poisson"""
        score_probs = {}
        btts = over15 = over25 = over35 = 0
        home_win = draw = away_win = 0
        
        for h in range(max_goals + 1):
            for a in range(max_goals + 1):
                prob = self._poisson_prob(home_xg, h) * self._poisson_prob(away_xg, a)
                score_probs[f"{h}-{a}"] = prob
                
                if h > a: home_win += prob
                elif h == a: draw += prob
                else: away_win += prob
                
                if h > 0 and a > 0: btts += prob
                total = h + a
                if total > 1: over15 += prob
                if total > 2: over25 += prob
                if total > 3: over35 += prob
        
        sorted_scores = sorted(score_probs.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {
            'home_xg': round(home_xg, 2),
            'away_xg': round(away_xg, 2),
            'total_xg': round(home_xg + away_xg, 2),
            'btts_prob': round(btts * 100, 1),
            'over15_prob': round(over15 * 100, 1),
            'over25_prob': round(over25 * 100, 1),
            'over35_prob': round(over35 * 100, 1),
            'most_likely_scores': [(s, round(p * 100, 1)) for s, p in sorted_scores],
            '1x2': {
                'home': round(home_win * 100, 1),
                'draw': round(draw * 100, 1),
                'away': round(away_win * 100, 1)
            }
        }
    
    # ============================================================
    # DATA RETRIEVAL
    # ============================================================
    
    def get_team_data(self, team_name: str) -> Optional[Dict]:
        """R√©cup√®re donn√©es compl√®tes d'une √©quipe"""
        conn = self._get_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        try:
            cur.execute("SELECT * FROM team_statistics_live WHERE team_name = %s", (team_name,))
            row = cur.fetchone()
            return dict(row) if row else None
        finally:
            cur.close()
            conn.close()
    
    def get_h2h_data(self, team_a: str, team_b: str) -> Optional[Dict]:
        """R√©cup√®re H2H"""
        conn = self._get_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        try:
            t1, t2 = sorted([team_a, team_b])
            cur.execute("""
                SELECT * FROM team_head_to_head 
                WHERE team_a = %s AND team_b = %s
            """, (t1, t2))
            row = cur.fetchone()
            return dict(row) if row else None
        finally:
            cur.close()
            conn.close()
    
    def _calculate_momentum(self, form: str, streak: str) -> float:
        """Calcule momentum (-1 √† +1)"""
        if not form:
            return 0.0
        
        momentum = 0.0
        weights = [0.35, 0.25, 0.20, 0.12, 0.08]
        
        for i, char in enumerate(form[:5]):
            if i < len(weights):
                if char == 'W':
                    momentum += weights[i]
                elif char == 'L':
                    momentum -= weights[i]
        
        if streak:
            try:
                streak_type = streak[0]
                streak_len = int(streak[1:]) if len(streak) > 1 else 1
                bonus = min(streak_len * 0.05, 0.2)
                if streak_type == 'W':
                    momentum += bonus
                elif streak_type == 'L':
                    momentum -= bonus
            except:
                pass
        
        return max(-1, min(1, momentum))
    
    # ============================================================
    # FEATURE EXTRACTION
    # ============================================================
    
    def extract_features(self, home_team: str, away_team: str) -> Optional[FeatureSet]:
        """Extrait les features pour ML"""
        home = self.get_team_data(home_team)
        away = self.get_team_data(away_team)
        h2h = self.get_h2h_data(home_team, away_team)
        
        if not home or not away:
            return None
        
        home_momentum = self._calculate_momentum(home.get('form', ''), home.get('current_streak', ''))
        away_momentum = self._calculate_momentum(away.get('form', ''), away.get('current_streak', ''))
        
        league = home.get('league', 'default')
        ha_factor = HOME_ADVANTAGE.get(league, HOME_ADVANTAGE['default'])
        
        # xG
        home_xg = self._safe_float(home.get('home_avg_scored'), 1.5) * ha_factor
        away_xg = self._safe_float(away.get('away_avg_scored'), 1.0) / ha_factor
        total_xg = home_xg + away_xg
        
        return FeatureSet(
            home_btts_pct=self._safe_float(home.get('btts_pct')),
            home_over25_pct=self._safe_float(home.get('over_25_pct')),
            home_avg_scored=self._safe_float(home.get('home_avg_scored'), 1.5),
            home_avg_conceded=self._safe_float(home.get('home_avg_conceded'), 1.0),
            home_clean_sheet_pct=self._safe_float(home.get('home_clean_sheet_pct'), 30),
            home_fts_pct=self._safe_float(home.get('failed_to_score_pct'), 20),
            home_last5_btts=self._safe_float(home.get('last5_btts_pct')),
            home_last5_over25=self._safe_float(home.get('last5_over25_pct')),
            home_form_points=home.get('last5_form_points', 0) or 0,
            home_momentum=home_momentum,
            home_matches=home.get('matches_played', 0),
            
            away_btts_pct=self._safe_float(away.get('btts_pct')),
            away_over25_pct=self._safe_float(away.get('over_25_pct')),
            away_avg_scored=self._safe_float(away.get('away_avg_scored'), 1.0),
            away_avg_conceded=self._safe_float(away.get('away_avg_conceded'), 1.5),
            away_clean_sheet_pct=self._safe_float(away.get('away_clean_sheet_pct'), 20),
            away_fts_pct=self._safe_float(away.get('failed_to_score_pct'), 20),
            away_last5_btts=self._safe_float(away.get('last5_btts_pct')),
            away_last5_over25=self._safe_float(away.get('last5_over25_pct')),
            away_form_points=away.get('last5_form_points', 0) or 0,
            away_momentum=away_momentum,
            away_matches=away.get('matches_played', 0),
            
            h2h_btts_pct=self._safe_float(h2h.get('btts_pct')) if h2h else 50,
            h2h_over25_pct=self._safe_float(h2h.get('over_25_pct')) if h2h else 50,
            h2h_avg_goals=self._safe_float(h2h.get('avg_total_goals'), 2.5) if h2h else 2.5,
            h2h_matches=h2h.get('total_matches', 0) if h2h else 0,
            
            total_xg=total_xg,
            home_advantage=ha_factor
        )
    
    # ============================================================
    # ML TRAINING
    # ============================================================
    
    def train_ml_models(self) -> Dict:
        """
        Entra√Æne les mod√®les ML sur les donn√©es historiques
        """
        if not ML_AVAILABLE:
            return {'error': 'ML non disponible - installer scikit-learn'}
        
        conn = self._get_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # R√©cup√©rer matchs termin√©s
        cur.execute("""
            SELECT home_team, away_team, score_home, score_away
            FROM match_results
            WHERE is_finished = true AND score_home IS NOT NULL
        """)
        matches = cur.fetchall()
        cur.close()
        conn.close()
        
        if len(matches) < 50:
            return {'error': f'Pas assez de donn√©es ({len(matches)} matchs, minimum 50)'}
        
        # Extraire features et targets
        X_list = []
        y_btts = []
        y_over25 = []
        
        for match in matches:
            features = self.extract_features(match['home_team'], match['away_team'])
            if features:
                X_list.append(features.to_array().flatten())
                y_btts.append(1 if match['score_home'] > 0 and match['score_away'] > 0 else 0)
                y_over25.append(1 if match['score_home'] + match['score_away'] > 2 else 0)
        
        if len(X_list) < 50:
            return {'error': f'Pas assez de features ({len(X_list)})'}
        
        X = np.array(X_list)
        y_btts = np.array(y_btts)
        y_over25 = np.array(y_over25)
        
        # Entra√Æner
        results = self.ml.train(X, y_btts, y_over25)
        
        # Sauvegarder
        self.ml.save()
        
        return {
            'samples': len(X_list),
            'btts_positive_rate': y_btts.mean() * 100,
            'over25_positive_rate': y_over25.mean() * 100,
            'performance': results
        }
    
    # ============================================================
    # PREDICTION ULTIMATE
    # ============================================================
    
    def calculate_score(self, features: FeatureSet, target: str, poisson_prob: float, h2h: Dict) -> Dict:
        """
        Calcule le score avec tous les mod√®les combin√©s
        """
        scores = {}
        
        # 1. Score Poisson (35%)
        scores['poisson'] = poisson_prob
        
        # 2. Score statistique (stats globales + sp√©cifiques + tendances)
        if target == 'btts':
            stats_global = (features.home_btts_pct + features.away_btts_pct) / 2
            stats_specific = (
                self._safe_float(None, features.home_btts_pct) + 
                self._safe_float(None, features.away_btts_pct)
            ) / 2
            stats_trends = (features.home_last5_btts + features.away_last5_btts) / 2
        else:
            stats_global = (features.home_over25_pct + features.away_over25_pct) / 2
            stats_specific = stats_global  # Utiliser global si sp√©cifique non dispo
            stats_trends = (features.home_last5_over25 + features.away_last5_over25) / 2
        
        scores['global'] = stats_global
        scores['specific'] = stats_specific
        scores['trends'] = stats_trends
        
        # 3. H2H
        if h2h and h2h.get('total_matches', 0) >= 2:
            if target == 'btts':
                scores['h2h'] = self._safe_float(h2h.get('btts_pct'))
            else:
                scores['h2h'] = self._safe_float(h2h.get('over_25_pct'))
        else:
            scores['h2h'] = (scores['global'] + scores['specific']) / 2
        
        # 4. ML prediction (si disponible)
        ml_pred = None
        if self.ml.is_trained:
            ml_result = self.ml.predict(features, target)
            if ml_result.get('probability'):
                ml_pred = ml_result['probability']
                scores['ml'] = ml_pred
        
        # Combiner avec poids calibr√©s
        weighted_score = 0
        total_weight = 0
        
        for factor, weight in self.weights.items():
            if factor in scores:
                weighted_score += scores[factor] * weight
                total_weight += weight
        
        # Ajouter ML si disponible (bonus)
        if ml_pred is not None:
            ml_weight = 0.20
            weighted_score = weighted_score * (1 - ml_weight) + ml_pred * ml_weight
        
        final_score = weighted_score / total_weight if total_weight > 0 else 50
        
        # P√©nalit√©s
        if target == 'btts':
            cs_penalty = (features.home_clean_sheet_pct + features.away_clean_sheet_pct) / 4
            fts_penalty = (features.home_fts_pct + features.away_fts_pct) / 4
            final_score -= (cs_penalty + fts_penalty)
        
        # Momentum bonus
        momentum_bonus = (features.home_momentum + features.away_momentum) * 3
        final_score += momentum_bonus
        
        final_score = max(0, min(100, final_score))
        
        return {
            'score': round(final_score, 1),
            'components': {k: round(v, 1) for k, v in scores.items()},
            'ml_prediction': ml_pred,
            'weights_used': self.weights
        }
    
    def calculate_confidence(self, features: FeatureSet, h2h: Dict, 
                            btts_score: float, over25_score: float) -> Tuple[Confidence, int]:
        """Calcule confidence multi-crit√®res"""
        score = 0
        
        # Matchs jou√©s
        matches = features.home_matches + features.away_matches
        score += min(matches / 30 * 25, 25)
        
        # H2H
        if h2h:
            score += min(h2h.get('total_matches', 0) / 5 * 15, 15)
        
        # Coh√©rence tendances
        home_coh = 100 - abs(features.home_btts_pct - features.home_last5_btts)
        away_coh = 100 - abs(features.away_btts_pct - features.away_last5_btts)
        score += ((home_coh + away_coh) / 2) / 100 * 20
        
        # ML disponible
        if self.ml.is_trained:
            score += 15
        
        # Score √©lev√© = plus de confiance
        avg_score = (btts_score + over25_score) / 2
        if avg_score >= 70 or avg_score <= 30:
            score += 15
        elif avg_score >= 60 or avg_score <= 40:
            score += 10
        
        conf_score = int(min(score, 100))
        
        if conf_score >= 90:
            return Confidence.DIAMOND, conf_score
        elif conf_score >= 75:
            return Confidence.PLATINUM, conf_score
        elif conf_score >= 60:
            return Confidence.GOLD, conf_score
        elif conf_score >= 45:
            return Confidence.SILVER, conf_score
        elif conf_score >= 30:
            return Confidence.BRONZE, conf_score
        else:
            return Confidence.IRON, conf_score
    
    def get_recommendation(self, score: float, confidence: Confidence) -> Recommendation:
        """Recommandation bas√©e sur score et confidence"""
        if score >= 80 and confidence in [Confidence.DIAMOND, Confidence.PLATINUM]:
            return Recommendation.DIAMOND_PICK
        if score >= 70 and confidence in [Confidence.DIAMOND, Confidence.PLATINUM]:
            return Recommendation.STRONG_YES
        if score >= 65 and confidence in [Confidence.DIAMOND, Confidence.PLATINUM, Confidence.GOLD]:
            return Recommendation.YES
        if score >= 55:
            return Recommendation.LEAN_YES
        if score >= 45:
            return Recommendation.NEUTRAL
        if score >= 35:
            return Recommendation.LEAN_NO
        if score >= 25 and confidence in [Confidence.DIAMOND, Confidence.PLATINUM, Confidence.GOLD]:
            return Recommendation.NO
        if score < 25 and confidence in [Confidence.DIAMOND, Confidence.PLATINUM]:
            return Recommendation.STRONG_NO
        return Recommendation.LEAN_NO
    
    def calculate_kelly(self, prob: float, odds: float, fraction: float = 0.25) -> float:
        """Kelly Criterion"""
        if not odds or odds <= 1 or prob <= 0:
            return 0.0
        
        p = prob / 100
        b = odds - 1
        q = 1 - p
        
        kelly = (b * p - q) / b
        kelly *= fraction
        
        return max(0, min(0.10, kelly))
    
    def calculate_value(self, prob: float, odds: float) -> Dict:
        """Value bet analysis"""
        if not odds or odds <= 1:
            return {'is_value': False, 'rating': 'N/A'}
        
        our_prob = prob / 100
        implied_prob = 1 / odds
        edge = our_prob - implied_prob
        ev = (our_prob * (odds - 1)) - (1 - our_prob)
        
        if edge >= 0.20:
            rating = "üíé DIAMOND VALUE"
        elif edge >= 0.15:
            rating = "üî• STRONG VALUE"
        elif edge >= 0.10:
            rating = "‚úÖ VALUE"
        elif edge >= 0.05:
            rating = "üìà SLIGHT VALUE"
        elif edge >= 0:
            rating = "‚öñÔ∏è FAIR"
        else:
            rating = "‚ùå AVOID"
        
        return {
            'is_value': edge >= 0.05,
            'our_prob': round(our_prob * 100, 1),
            'implied_prob': round(implied_prob * 100, 1),
            'edge': round(edge * 100, 2),
            'ev': round(ev * 100, 2),
            'rating': rating
        }
    
    def predict_match(self, home_team: str, away_team: str,
                      odds_btts: float = None, odds_over25: float = None) -> Dict:
        """
        Pr√©diction ULTIMATE avec tous les mod√®les
        """
        # Extract features
        features = self.extract_features(home_team, away_team)
        if not features:
            return {'error': '√âquipe non trouv√©e', 'home': home_team, 'away': away_team}
        
        home = self.get_team_data(home_team)
        away = self.get_team_data(away_team)
        h2h = self.get_h2h_data(home_team, away_team)
        
        league = home.get('league', 'Unknown') if home else 'Unknown'
        
        # Poisson
        poisson = self.calculate_poisson(features.total_xg * 0.5, features.total_xg * 0.5)
        # Recalculer avec vrais xG
        home_xg = features.home_avg_scored * features.home_advantage
        away_xg = features.away_avg_scored / features.home_advantage
        poisson = self.calculate_poisson(home_xg, away_xg)
        
        # Scores
        btts_data = self.calculate_score(features, 'btts', poisson['btts_prob'], h2h)
        over25_data = self.calculate_score(features, 'over25', poisson['over25_prob'], h2h)
        
        # Confidence
        confidence, conf_score = self.calculate_confidence(
            features, h2h, btts_data['score'], over25_data['score']
        )
        
        # Recommendations
        btts_rec = self.get_recommendation(btts_data['score'], confidence)
        over25_rec = self.get_recommendation(over25_data['score'], confidence)
        
        # Value & Kelly
        btts_value = self.calculate_value(btts_data['score'], odds_btts) if odds_btts else {}
        over25_value = self.calculate_value(over25_data['score'], odds_over25) if odds_over25 else {}
        btts_kelly = self.calculate_kelly(btts_data['score'], odds_btts) if odds_btts else 0
        over25_kelly = self.calculate_kelly(over25_data['score'], odds_over25) if odds_over25 else 0
        
        # Match interest
        max_score = max(btts_data['score'], over25_data['score'])
        if max_score >= 80 and confidence in [Confidence.DIAMOND, Confidence.PLATINUM]:
            interest = "üíé DIAMOND MATCH"
        elif max_score >= 70:
            interest = "üî• HIGH INTEREST"
        elif max_score >= 60:
            interest = "üìà MEDIUM INTEREST"
        else:
            interest = "üìä LOW INTEREST"
        
        return {
            'match': {
                'home_team': home_team,
                'away_team': away_team,
                'league': league
            },
            'poisson': poisson,
            'btts': {
                'score': btts_data['score'],
                'recommendation': btts_rec.value,
                'components': btts_data['components'],
                'ml_prediction': btts_data.get('ml_prediction')
            },
            'over25': {
                'score': over25_data['score'],
                'recommendation': over25_rec.value,
                'expected_goals': poisson['total_xg'],
                'components': over25_data['components'],
                'ml_prediction': over25_data.get('ml_prediction')
            },
            'confidence': {
                'level': confidence.value,
                'score': conf_score,
                'emoji': 'üíé' if confidence == Confidence.DIAMOND else
                         'üèÜ' if confidence == Confidence.PLATINUM else
                         'ü•á' if confidence == Confidence.GOLD else
                         'ü•à' if confidence == Confidence.SILVER else
                         'ü•â' if confidence == Confidence.BRONZE else '‚ö´'
            },
            'value': {
                'btts': btts_value,
                'over25': over25_value
            },
            'kelly': {
                'btts': round(btts_kelly * 100, 2),
                'over25': round(over25_kelly * 100, 2)
            },
            'ml_enabled': self.ml.is_trained,
            'weights': self.weights,
            'match_interest': interest,
            'generated_at': datetime.now().isoformat()
        }
    
    def run_backtest(self, strategy: str = 'btts', min_score: float = 65) -> BacktestResult:
        """Lance un backtest"""
        return self.backtester.run_backtest(strategy=strategy, min_score=min_score)
    
    def recalibrate_weights(self) -> Dict:
        """Recalibre les poids bas√© sur performance"""
        # R√©cup√©rer r√©sultats r√©cents
        conn = self._get_conn()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        cur.execute("""
            SELECT * FROM market_predictions
            WHERE prediction_correct_btts IS NOT NULL
            ORDER BY match_date DESC
            LIMIT 100
        """)
        
        results = cur.fetchall()
        cur.close()
        conn.close()
        
        new_weights = self.calibrator.calibrate(results)
        self.weights = new_weights
        
        return new_weights
